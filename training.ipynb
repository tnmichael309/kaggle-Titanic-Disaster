{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 42)\n",
      "(418, 41)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/preprocessed_train.csv')\n",
    "test = pd.read_csv('data/preprocessed_test.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(train.columns)\n",
    "\n",
    "target = 'Survived'\n",
    "features.remove(target)\n",
    "\n",
    "train_x = train[features]\n",
    "train_y = train[target]\n",
    "test_x = test[features]\n",
    "\n",
    "train_num = train_x.shape[0]\n",
    "test_num = test_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    549\n",
      "1.0    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dead_weight = 549/891.0\n",
    "survived_weight = 1.0 - dead_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperate into two groups, one can predict prob for soft voting classifier, another group cannot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1: Classifiers with predict_prob functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 31.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.6, 'alpha': 0.005} 0.808082454455\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log', penalty='elasticnet', class_weight = 'balanced', n_jobs=4,\n",
    "                    alpha=0.0005, l1_ratio=0.87, random_state=3, max_iter=100000, learning_rate='optimal')\n",
    "params = {\n",
    "    'alpha': [0.05, 0.01, 0.005, 0.001],\n",
    "    'l1_ratio': [1.0, 0.8, 0.6],\n",
    "    #'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=sgd, param_grid = params, scoring='accuracy', iid=False, cv=5, verbose=1)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 3} 0.808082454455\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log', penalty='elasticnet', class_weight = 'balanced', n_jobs=2,\n",
    "                    alpha=0.005, l1_ratio=0.6, random_state=3, max_iter=100000, learning_rate='optimal')\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=sgd, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2'} 0.809243996089\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight = 'balanced', random_state=3, max_iter=100000)\n",
    "\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "gs =  GridSearchCV(estimator=lr, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1} 0.809243996089\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight = 'balanced', penalty='l2', random_state=3, max_iter=100000)\n",
    "\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=lr, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0005} 0.813776395167\n"
     ]
    }
   ],
   "source": [
    "# use lbfgs for small data set\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), solver='lbfgs', alpha=0.001, random_state=3, \n",
    "                    max_iter=10000)\n",
    "params = {\n",
    "    'alpha': [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005],\n",
    "}\n",
    "gs =  GridSearchCV(estimator=mlp, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 3} 0.813776395167\n"
     ]
    }
   ],
   "source": [
    "# use lbfgs for small data set\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), solver='lbfgs', alpha=0.0005, random_state=3, \n",
    "                    max_iter=10000)\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=mlp, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_impurity_decrease': 0.001, 'min_samples_split': 0.01, 'min_weight_fraction_leaf': 0.0} 0.831697429629\n"
     ]
    }
   ],
   "source": [
    "# use lbfgs for small data set\n",
    "rf = RandomForestClassifier(n_estimators = 1200, n_jobs = 2, class_weight='balanced',\n",
    "                            random_state=3,\n",
    "                            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                            min_impurity_decrease=0.0,)\n",
    "params = {\n",
    "    'min_samples_split': [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3, 0.4, 0.49],\n",
    "    'min_impurity_decrease': [0.2, 0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "}\n",
    "gs =  GridSearchCV(estimator=rf, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 3} 0.831697429629\n"
     ]
    }
   ],
   "source": [
    "# use lbfgs for small data set\n",
    "rf = RandomForestClassifier(n_estimators = 1200, n_jobs = 2, class_weight='balanced',\n",
    "                            random_state=3,\n",
    "                            min_samples_split=0.01, min_weight_fraction_leaf=0.0,\n",
    "                            min_impurity_decrease=0.001)\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=rf, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_prior': [0.5, 0.5], 'alpha': 0.2, 'fit_prior': True} 0.707246965817\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB() #priors=[survived_weight, dead_weight])\n",
    "params = {\n",
    "    'alpha': [1.0, 0.8, 0.6, 0.4, 0.2, 0.1],\n",
    "    'fit_prior': [True, False],\n",
    "    'class_prior':[[survived_weight, dead_weight], [.5, .5], [dead_weight, survived_weight]]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=nb, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.01} 0.848513770721\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=1, colsample_bytree=1,\n",
    "                      min_child_weight=0.0, gamma=0.0,\n",
    "                      reg_alpha=0, reg_lambda=1,random_state=0, objective = 'binary:logistic', eval_metric='logloss')\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.05],\n",
    "    'subsample': [1.0, 0.8, 0.6], \n",
    "    'colsample_bytree': [1.0, 0.8, 0.6], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=xg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_weight': 0.3, 'gamma': 0.2} 0.850748407592\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=.8, colsample_bytree=.8,\n",
    "                      min_child_weight=0.0, gamma=0.0,\n",
    "                      reg_alpha=0, reg_lambda=1, random_state=0, objective = 'binary:logistic', eval_metric='logloss')\n",
    "\n",
    "params = {\n",
    "    'min_child_weight': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'gamma': [0.0, 0.01, 0.05, 0.1, 0.2, 0.4], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=xg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_lambda': 1.0, 'reg_alpha': 0.0} 0.850748407592\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=.8, colsample_bytree=.8,\n",
    "                      min_child_weight=0.3, gamma=0.2,\n",
    "                      reg_alpha=0, reg_lambda=1, random_state=0, objective = 'binary:logistic', eval_metric='logloss')\n",
    "\n",
    "params = {\n",
    "    'reg_alpha': [0.0, .2, .4, .6, .8, 1.],\n",
    "    'reg_lambda': [0.0, .2, .4, .6, .8, 1.], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=xg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 0} 0.850748407592\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=.8, colsample_bytree=.8,\n",
    "                      min_child_weight=0.3, gamma=0.2,\n",
    "                      reg_alpha=0, reg_lambda=1, random_state=0, objective = 'binary:logistic', eval_metric='logloss')\n",
    "\n",
    "params = {\n",
    "    'random_state': [0, 1, 2, 3, 4, 5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=xg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.005} 0.840667362464\n"
     ]
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.01, subsample = 1.0, colsample_bytree=1.0,\n",
    "                       min_child_samples = 1, min_child_weight=0.0, min_split_gain=0.01,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05],\n",
    "    'subsample': [1.0, 0.8, 0.6, 0.4, 0.2, 0.1], \n",
    "    'colsample_bytree': [1.0, 0.8, 0.6, 0.4, 0.2, 0.1], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=lg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_split_gain': 0.0, 'min_child_weight': 1.6, 'min_child_samples': 1} 0.849649849439\n"
     ]
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.005, subsample = .4, colsample_bytree=.6,\n",
    "                       min_child_samples = 1, min_child_weight=0.0, min_split_gain=0.01,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'min_child_samples': [1, 2, 4, 8, 16, 32],\n",
    "    'min_child_weight': [0.2, 0.4, 0.8, 1.6, 3.2], \n",
    "    'min_split_gain': [0.0, 0.01, 0.05, 0.1, 0.2, 0.4], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=lg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_lambda': 0.0, 'reg_alpha': 0.0} 0.849649849439\n"
     ]
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.005, subsample = .4, colsample_bytree=.6,\n",
    "                       min_child_samples = 1, min_child_weight=1.6, min_split_gain=0.0,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'reg_alpha': [0.0, .2, .4, .6, .8, 1.],\n",
    "    'reg_lambda': [0.0, .2, .4, .6, .8, 1.], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=lg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 5} 0.849668822503\n"
     ]
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.005, subsample = .4, colsample_bytree=.6,\n",
    "                       min_child_samples = 1, min_child_weight=1.6, min_split_gain=0.0,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'random_state': [0,1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=lg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.808082454455\n",
    "sgd = SGDClassifier(loss='log', penalty='elasticnet', class_weight = 'balanced', n_jobs=2,\n",
    "                    alpha=0.005, l1_ratio=0.6, random_state=3, max_iter=100000, learning_rate='optimal')\n",
    "\n",
    "# 0.809243996089\n",
    "lr = LogisticRegression(class_weight = 'balanced', penalty='l2', random_state=1, max_iter=100000)\n",
    "\n",
    "# 0.813776395167\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), solver='lbfgs', alpha=0.0005, random_state=3, \n",
    "                    max_iter=10000)\n",
    "\n",
    "# 0.831697429629\n",
    "rf = RandomForestClassifier(n_estimators = 1200, n_jobs = 2, class_weight='balanced',\n",
    "                            random_state=3,\n",
    "                            min_samples_split=0.01, min_weight_fraction_leaf=0.0,\n",
    "                            min_impurity_decrease=0.001)\n",
    "\n",
    "# 0.849668822503\n",
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.005, subsample = .4, colsample_bytree=.6,\n",
    "                       min_child_samples = 1, min_child_weight=1.6, min_split_gain=0.0,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=5)\n",
    "\n",
    "# 0.850748407592\n",
    "xg = xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=.8, colsample_bytree=.8,\n",
    "                      min_child_weight=0.3, gamma=0.2,\n",
    "                      reg_alpha=0, reg_lambda=1, random_state=0, objective = 'binary:logistic', eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 2: Classifiers without predict_prob functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.6} 0.82046753886\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier(alpha=1.0, normalize=True, class_weight='balanced', random_state=3, max_iter=10000)\n",
    "params = {\n",
    "    'alpha': [1.0, 0.8, 0.6, 0.4, 0.2],\n",
    "}\n",
    "gs =  GridSearchCV(estimator=ridge, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1} 0.82046753886\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier(alpha=0.6, normalize=True, class_weight='balanced', random_state=3, max_iter=10000)\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=ridge, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.82046753886\n",
    "ridge = RidgeClassifier(alpha=0.6, normalize=True, class_weight='balanced', random_state=3, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Group1 + 2 (cv accuracy < 0.83) for voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use hard voting since these models are not well-calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VotingClassifier(estimators=[('lr', lr), ('sgd', sgd), ('ridge', ridge), ('mlp', mlp)], \n",
    "                 voting='hard', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81005587,  0.79329609,  0.81460674,  0.82022472,  0.83615819])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(vc, train_x, train_y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81486832200000003"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([ 0.81005587,  0.79329609,  0.81460674,  0.82022472,  0.83615819]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VotingClassifier(estimators=[('lr', lr), ('sgd', sgd), ('ridge', ridge), ('mlp', mlp)], \n",
    "                 voting='hard', n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Group1 + 2 (cv accuracy < 0.83) in the stacking averaged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stacking_models_api import StackingAveragedModels\n",
    "from cross_valid_api import cross_validate\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supervised_dict = {\n",
    "    'ridge': ridge,\n",
    "    'lr': lr,\n",
    "    'sgd': sgd,\n",
    "    'mlp': mlp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sam = StackingAveragedModels(sl_base_models_dict=supervised_dict, meta_model=rf, target_col='Survived', eval_func=accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.804195804196\n",
      "score= 0.776223776224\n",
      "score= 0.802816901408\n",
      "score= 0.830985915493\n",
      "score= 0.838028169014\n",
      "Avg score =  0.810450113267\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.755244755245\n",
      "score= 0.776223776224\n",
      "score= 0.760563380282\n",
      "score= 0.795774647887\n",
      "score= 0.838028169014\n",
      "Avg score =  0.78516694573\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.755244755245\n",
      "score= 0.776223776224\n",
      "score= 0.788732394366\n",
      "score= 0.852112676056\n",
      "score= 0.838028169014\n",
      "Avg score =  0.802068354181\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.804195804196\n",
      "score= 0.783216783217\n",
      "score= 0.781690140845\n",
      "score= 0.838028169014\n",
      "score= 0.852112676056\n",
      "Avg score =  0.811848714666\n",
      "meta model's training set score=  0.818820224719 \n",
      "\n",
      "fold  1  valid score:  0.843575418994\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.811188811189\n",
      "score= 0.804195804196\n",
      "score= 0.762237762238\n",
      "score= 0.788732394366\n",
      "score= 0.795774647887\n",
      "Avg score =  0.792425883975\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.783216783217\n",
      "score= 0.839160839161\n",
      "score= 0.734265734266\n",
      "score= 0.830985915493\n",
      "score= 0.795774647887\n",
      "Avg score =  0.796680784005\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.811188811189\n",
      "score= 0.825174825175\n",
      "score= 0.776223776224\n",
      "score= 0.823943661972\n",
      "score= 0.795774647887\n",
      "Avg score =  0.806461144489\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.825174825175\n",
      "score= 0.832167832168\n",
      "score= 0.797202797203\n",
      "score= 0.816901408451\n",
      "score= 0.774647887324\n",
      "Avg score =  0.809218950064\n",
      "meta model's training set score=  0.816269284712 \n",
      "\n",
      "fold  2  valid score:  0.825842696629\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.818181818182\n",
      "score= 0.797202797203\n",
      "score= 0.755244755245\n",
      "score= 0.80985915493\n",
      "score= 0.816901408451\n",
      "Avg score =  0.799477986802\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.846153846154\n",
      "score= 0.741258741259\n",
      "score= 0.748251748252\n",
      "score= 0.816901408451\n",
      "score= 0.816901408451\n",
      "Avg score =  0.793893430513\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.811188811189\n",
      "score= 0.804195804196\n",
      "score= 0.804195804196\n",
      "score= 0.80985915493\n",
      "score= 0.795774647887\n",
      "Avg score =  0.805042844479\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.825174825175\n",
      "score= 0.818181818182\n",
      "score= 0.79020979021\n",
      "score= 0.823943661972\n",
      "score= 0.816901408451\n",
      "Avg score =  0.814882300798\n",
      "meta model's training set score=  0.820476858345 \n",
      "\n",
      "fold  3  valid score:  0.831460674157\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.825174825175\n",
      "score= 0.769230769231\n",
      "score= 0.818181818182\n",
      "score= 0.795774647887\n",
      "score= 0.838028169014\n",
      "Avg score =  0.809278045898\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.818181818182\n",
      "score= 0.79020979021\n",
      "score= 0.804195804196\n",
      "score= 0.788732394366\n",
      "score= 0.830985915493\n",
      "Avg score =  0.806461144489\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.825174825175\n",
      "score= 0.804195804196\n",
      "score= 0.804195804196\n",
      "score= 0.795774647887\n",
      "score= 0.852112676056\n",
      "Avg score =  0.816290751502\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.832167832168\n",
      "score= 0.804195804196\n",
      "score= 0.839160839161\n",
      "score= 0.823943661972\n",
      "score= 0.866197183099\n",
      "Avg score =  0.833133064119\n",
      "meta model's training set score=  0.833099579243 \n",
      "\n",
      "fold  4  valid score:  0.803370786517\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.79020979021\n",
      "score= 0.79020979021\n",
      "score= 0.874125874126\n",
      "score= 0.767605633803\n",
      "score= 0.866197183099\n",
      "Avg score =  0.817669654289\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.818181818182\n",
      "score= 0.776223776224\n",
      "score= 0.874125874126\n",
      "score= 0.816901408451\n",
      "score= 0.880281690141\n",
      "Avg score =  0.833142913425\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.797202797203\n",
      "score= 0.783216783217\n",
      "score= 0.86013986014\n",
      "score= 0.802816901408\n",
      "score= 0.880281690141\n",
      "Avg score =  0.824731606422\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.818181818182\n",
      "score= 0.783216783217\n",
      "score= 0.874125874126\n",
      "score= 0.788732394366\n",
      "score= 0.859154929577\n",
      "Avg score =  0.824682359894\n",
      "meta model's training set score=  0.833099579243 \n",
      "\n",
      "fold  5  valid score:  0.803370786517\n",
      "5  fold(s) avg. valid score:  0.821524072563\n"
     ]
    }
   ],
   "source": [
    "cross_validate(sam, train_x, train_y, 5, scoring=accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CV result is slightly better when using stacking averaged model than using hard-voting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the final classifier by combining the stacking averaged model with rf, xgboost and lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_vc = VotingClassifier(estimators=[('sam', sam), ('rf', rf), ('lg', lg), ('xg', xg)], \n",
    "                 voting='soft', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': [0.03, 0.07, 0.45, 0.45]} 0.846285410919\n"
     ]
    }
   ],
   "source": [
    "weights = np.arange(4)\n",
    "\n",
    "params = {\n",
    "    'weights': [weights, \n",
    "                [.1, .2, .35, .35],\n",
    "                [.05, .15, .4, .4],\n",
    "                [.03, .07,.45, .45],\n",
    "                [.005, .015, .49, .49],\n",
    "                [.25, .25, .25, .25]]\n",
    "}\n",
    "\n",
    "gs =  GridSearchCV(estimator=final_vc, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_vc_soft = VotingClassifier(estimators=[('sam', sam), ('rf', rf), ('lg', lg), ('xg', xg)], \n",
    "                 weights = [.03, .07,.45, .45],\n",
    "                 voting='soft', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1  valid score:  0.871508379888\n",
      "fold  2  valid score:  0.820224719101\n",
      "fold  3  valid score:  0.848314606742\n",
      "fold  4  valid score:  0.837078651685\n",
      "fold  5  valid score:  0.797752808989\n",
      "5  fold(s) avg. valid score:  0.834975833281\n"
     ]
    }
   ],
   "source": [
    "cross_validate(final_vc_soft, train_x, train_y, 5, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sam', StackingAveragedModels(eval_func=<function accuracy_score at 0x000000000AFFC048>,\n",
       "            meta_model=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurit...      reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8))],\n",
       "         flatten_transform=None, n_jobs=2, voting='soft',\n",
       "         weights=[0.03, 0.07, 0.45, 0.45])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_soft.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,\n",
       "        1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,\n",
       "        0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
       "        0.,  1.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_soft.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91126272,  0.05873728],\n",
       "       [ 0.76202499,  0.20797501],\n",
       "       [ 0.88698991,  0.0830101 ],\n",
       "       [ 0.72221612,  0.24778388],\n",
       "       [ 0.39051834,  0.57948166],\n",
       "       [ 0.88602573,  0.08397426],\n",
       "       [ 0.41465992,  0.55534008],\n",
       "       [ 0.82296474,  0.14703527],\n",
       "       [ 0.12312006,  0.84687994],\n",
       "       [ 0.9173401 ,  0.05265991],\n",
       "       [ 0.91994093,  0.05005908],\n",
       "       [ 0.9069623 ,  0.06303769],\n",
       "       [ 0.02544993,  0.94455007],\n",
       "       [ 0.92425085,  0.04574915],\n",
       "       [ 0.04809482,  0.92190518],\n",
       "       [ 0.06418925,  0.90581075],\n",
       "       [ 0.82128989,  0.14871012],\n",
       "       [ 0.76068599,  0.20931401],\n",
       "       [ 0.40299299,  0.56700701],\n",
       "       [ 0.44639423,  0.52360577],\n",
       "       [ 0.85905791,  0.11094209],\n",
       "       [ 0.66156198,  0.30843802],\n",
       "       [ 0.05453049,  0.91546951],\n",
       "       [ 0.77892372,  0.19107628],\n",
       "       [ 0.04052555,  0.92947445],\n",
       "       [ 0.93329621,  0.03670379],\n",
       "       [ 0.02878268,  0.94121732],\n",
       "       [ 0.84124129,  0.1287587 ],\n",
       "       [ 0.55820983,  0.41179017],\n",
       "       [ 0.82123332,  0.14876667],\n",
       "       [ 0.90996176,  0.06003823],\n",
       "       [ 0.89608909,  0.07391092],\n",
       "       [ 0.38732504,  0.58267496],\n",
       "       [ 0.58087494,  0.38912506],\n",
       "       [ 0.6306123 ,  0.33938771],\n",
       "       [ 0.83204958,  0.13795041],\n",
       "       [ 0.66696692,  0.30303308],\n",
       "       [ 0.68768503,  0.28231499],\n",
       "       [ 0.88769751,  0.08230248],\n",
       "       [ 0.62490805,  0.34509195],\n",
       "       [ 0.8804182 ,  0.08958181],\n",
       "       [ 0.38830001,  0.58169999],\n",
       "       [ 0.92223732,  0.04776269],\n",
       "       [ 0.07367472,  0.89632528],\n",
       "       [ 0.02498722,  0.94501278],\n",
       "       [ 0.83601015,  0.13398985],\n",
       "       [ 0.52045098,  0.44954903],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.02790133,  0.94209867],\n",
       "       [ 0.39805616,  0.57194384],\n",
       "       [ 0.75773852,  0.21226148],\n",
       "       [ 0.76784245,  0.20215756],\n",
       "       [ 0.11263495,  0.85736505],\n",
       "       [ 0.15384993,  0.81615007],\n",
       "       [ 0.79610873,  0.17389127],\n",
       "       [ 0.88187401,  0.08812599],\n",
       "       [ 0.85026607,  0.11973395],\n",
       "       [ 0.79603439,  0.17396561],\n",
       "       [ 0.89360475,  0.07639525],\n",
       "       [ 0.01920684,  0.95079316],\n",
       "       [ 0.88772858,  0.08227141],\n",
       "       [ 0.77208329,  0.19791671],\n",
       "       [ 0.87454176,  0.09545824],\n",
       "       [ 0.21220977,  0.75779023],\n",
       "       [ 0.19958704,  0.77041296],\n",
       "       [ 0.06949331,  0.90050669],\n",
       "       [ 0.24937811,  0.72062189],\n",
       "       [ 0.87804484,  0.09195516],\n",
       "       [ 0.41724329,  0.55275671],\n",
       "       [ 0.12474449,  0.84525551],\n",
       "       [ 0.25235688,  0.71764312],\n",
       "       [ 0.91596172,  0.05403828],\n",
       "       [ 0.37466288,  0.59533712],\n",
       "       [ 0.60185631,  0.36814369],\n",
       "       [ 0.03082007,  0.93917993],\n",
       "       [ 0.73256059,  0.23743941],\n",
       "       [ 0.90065085,  0.06934914],\n",
       "       [ 0.13676625,  0.83323375],\n",
       "       [ 0.88300817,  0.08699182],\n",
       "       [ 0.25235688,  0.71764312],\n",
       "       [ 0.13825181,  0.83174819],\n",
       "       [ 0.83997418,  0.13002582],\n",
       "       [ 0.83815663,  0.13184336],\n",
       "       [ 0.91994093,  0.05005908],\n",
       "       [ 0.81134182,  0.15865819],\n",
       "       [ 0.90213283,  0.06786718],\n",
       "       [ 0.13146272,  0.83853728],\n",
       "       [ 0.42073826,  0.54926174],\n",
       "       [ 0.23973741,  0.73026259],\n",
       "       [ 0.12165889,  0.84834111],\n",
       "       [ 0.43424155,  0.53575845],\n",
       "       [ 0.88365305,  0.08634695],\n",
       "       [ 0.04649714,  0.92350286],\n",
       "       [ 0.90065085,  0.06934914],\n",
       "       [ 0.74094809,  0.22905191],\n",
       "       [ 0.8255448 ,  0.14445521],\n",
       "       [ 0.07170227,  0.89829773],\n",
       "       [ 0.6650667 ,  0.30493328],\n",
       "       [ 0.44007568,  0.52992432],\n",
       "       [ 0.86388782,  0.10611218],\n",
       "       [ 0.03907043,  0.93092957],\n",
       "       [ 0.86259467,  0.10740535],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.71772762,  0.25227238],\n",
       "       [ 0.19606828,  0.77393172],\n",
       "       [ 0.89075861,  0.0792414 ],\n",
       "       [ 0.8732377 ,  0.0967623 ],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.90376591,  0.06623407],\n",
       "       [ 0.68478933,  0.28521067],\n",
       "       [ 0.90659544,  0.06340456],\n",
       "       [ 0.2261971 ,  0.7438029 ],\n",
       "       [ 0.02740803,  0.94259197],\n",
       "       [ 0.23713078,  0.73286922],\n",
       "       [ 0.08849325,  0.88150675],\n",
       "       [ 0.89965107,  0.07034893],\n",
       "       [ 0.91526293,  0.05473706],\n",
       "       [ 0.14657627,  0.82342373],\n",
       "       [ 0.46223242,  0.50776758],\n",
       "       [ 0.0946976 ,  0.8753024 ],\n",
       "       [ 0.08130066,  0.88869934],\n",
       "       [ 0.89437922,  0.07562077],\n",
       "       [ 0.02058639,  0.94941361],\n",
       "       [ 0.89942706,  0.07057295],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.48815098,  0.481849  ],\n",
       "       [ 0.86441572,  0.10558429],\n",
       "       [ 0.26269455,  0.70730545],\n",
       "       [ 0.81679806,  0.15320193],\n",
       "       [ 0.89172248,  0.07827752],\n",
       "       [ 0.68513852,  0.28486148],\n",
       "       [ 0.6560444 ,  0.3139556 ],\n",
       "       [ 0.83697251,  0.1330275 ],\n",
       "       [ 0.92199814,  0.04800185],\n",
       "       [ 0.92912259,  0.04087741],\n",
       "       [ 0.89255294,  0.07744707],\n",
       "       [ 0.83993399,  0.13006602],\n",
       "       [ 0.83630674,  0.13369327],\n",
       "       [ 0.60283121,  0.36716879],\n",
       "       [ 0.93032742,  0.03967258],\n",
       "       [ 0.90030867,  0.06969133],\n",
       "       [ 0.04635667,  0.92364333],\n",
       "       [ 0.80030131,  0.16969868],\n",
       "       [ 0.89000681,  0.07999319],\n",
       "       [ 0.51144893,  0.45855108],\n",
       "       [ 0.86120911,  0.10879089],\n",
       "       [ 0.5975684 ,  0.3724316 ],\n",
       "       [ 0.88834716,  0.08165284],\n",
       "       [ 0.6491458 ,  0.32085421],\n",
       "       [ 0.80551752,  0.16448248],\n",
       "       [ 0.02424211,  0.94575789],\n",
       "       [ 0.8827131 ,  0.08728691],\n",
       "       [ 0.92378871,  0.04621129],\n",
       "       [ 0.41596761,  0.55403239],\n",
       "       [ 0.76484243,  0.20515756],\n",
       "       [ 0.88267551,  0.08732449],\n",
       "       [ 0.05924345,  0.91075655],\n",
       "       [ 0.47355821,  0.49644179],\n",
       "       [ 0.26449817,  0.70550183],\n",
       "       [ 0.49997636,  0.47002364],\n",
       "       [ 0.25107047,  0.71892953],\n",
       "       [ 0.25253257,  0.71746743],\n",
       "       [ 0.12777517,  0.84222483],\n",
       "       [ 0.928462  ,  0.04153799],\n",
       "       [ 0.81341303,  0.15658696],\n",
       "       [ 0.5224072 ,  0.4475928 ],\n",
       "       [ 0.65420384,  0.31579616],\n",
       "       [ 0.93038918,  0.03961082],\n",
       "       [ 0.0660899 ,  0.9039101 ],\n",
       "       [ 0.64240349,  0.32759652],\n",
       "       [ 0.92215752,  0.04784248],\n",
       "       [ 0.52471949,  0.44528052],\n",
       "       [ 0.90021235,  0.06978764],\n",
       "       [ 0.87626265,  0.09373736],\n",
       "       [ 0.87007573,  0.09992428],\n",
       "       [ 0.08109012,  0.88890988],\n",
       "       [ 0.09705164,  0.87294836],\n",
       "       [ 0.71362881,  0.25637118],\n",
       "       [ 0.055032  ,  0.914968  ],\n",
       "       [ 0.0480111 ,  0.9219889 ],\n",
       "       [ 0.88300817,  0.08699182],\n",
       "       [ 0.40669279,  0.56330721],\n",
       "       [ 0.03258097,  0.93741903],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.02981753,  0.94018247],\n",
       "       [ 0.8589806 ,  0.11101942],\n",
       "       [ 0.1522229 ,  0.8177771 ],\n",
       "       [ 0.80710968,  0.16289031],\n",
       "       [ 0.81460691,  0.15539308],\n",
       "       [ 0.84594577,  0.12405423],\n",
       "       [ 0.87321857,  0.09678144],\n",
       "       [ 0.82431793,  0.14568207],\n",
       "       [ 0.41607942,  0.55392058],\n",
       "       [ 0.90602491,  0.0639751 ],\n",
       "       [ 0.20493436,  0.76506564],\n",
       "       [ 0.89235153,  0.07764846],\n",
       "       [ 0.05427705,  0.91572295],\n",
       "       [ 0.37458376,  0.59541624],\n",
       "       [ 0.89323761,  0.0767624 ],\n",
       "       [ 0.51133436,  0.45866564],\n",
       "       [ 0.25986453,  0.71013547],\n",
       "       [ 0.13394707,  0.83605293],\n",
       "       [ 0.51769138,  0.45230862],\n",
       "       [ 0.08444644,  0.88555356],\n",
       "       [ 0.89887057,  0.07112943],\n",
       "       [ 0.80199213,  0.16800789],\n",
       "       [ 0.30770574,  0.66229426],\n",
       "       [ 0.91645455,  0.05354544],\n",
       "       [ 0.03649261,  0.93350739],\n",
       "       [ 0.90147673,  0.06852327],\n",
       "       [ 0.70640014,  0.26359985],\n",
       "       [ 0.92913288,  0.04086712],\n",
       "       [ 0.82413646,  0.14586353],\n",
       "       [ 0.13596202,  0.83403798],\n",
       "       [ 0.72205036,  0.24794966],\n",
       "       [ 0.60535911,  0.3646409 ],\n",
       "       [ 0.2204107 ,  0.7495893 ],\n",
       "       [ 0.8673486 ,  0.10265141],\n",
       "       [ 0.07026389,  0.89973611],\n",
       "       [ 0.90065085,  0.06934914],\n",
       "       [ 0.12397304,  0.84602696],\n",
       "       [ 0.88754234,  0.08245765],\n",
       "       [ 0.08219221,  0.88780779],\n",
       "       [ 0.86719625,  0.10280374],\n",
       "       [ 0.11925263,  0.85074737],\n",
       "       [ 0.38780465,  0.58219535],\n",
       "       [ 0.85856361,  0.11143641],\n",
       "       [ 0.23973741,  0.73026259],\n",
       "       [ 0.93443064,  0.03556938],\n",
       "       [ 0.8759207 ,  0.0940793 ],\n",
       "       [ 0.81029023,  0.15970978],\n",
       "       [ 0.09691174,  0.87308826],\n",
       "       [ 0.91314316,  0.05685685],\n",
       "       [ 0.87054963,  0.09945038],\n",
       "       [ 0.52312115,  0.44687886],\n",
       "       [ 0.86770088,  0.10229913],\n",
       "       [ 0.75022668,  0.21977333],\n",
       "       [ 0.71245678,  0.25754322],\n",
       "       [ 0.1173243 ,  0.8526757 ],\n",
       "       [ 0.03670622,  0.93329378],\n",
       "       [ 0.14341381,  0.82658619],\n",
       "       [ 0.08582743,  0.88417257],\n",
       "       [ 0.40415084,  0.56584916],\n",
       "       [ 0.91994093,  0.05005908],\n",
       "       [ 0.6508438 ,  0.31915621],\n",
       "       [ 0.70812062,  0.26187937],\n",
       "       [ 0.08578982,  0.88421018],\n",
       "       [ 0.82581258,  0.14418742],\n",
       "       [ 0.0946976 ,  0.8753024 ],\n",
       "       [ 0.45701184,  0.51298816],\n",
       "       [ 0.0666599 ,  0.9033401 ],\n",
       "       [ 0.78788087,  0.18211913],\n",
       "       [ 0.43289264,  0.53710736],\n",
       "       [ 0.9165461 ,  0.0534539 ],\n",
       "       [ 0.91468896,  0.05531103],\n",
       "       [ 0.92215752,  0.04784248],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.87782038,  0.09217963],\n",
       "       [ 0.09475157,  0.87524843],\n",
       "       [ 0.87625592,  0.09374409],\n",
       "       [ 0.91916699,  0.050833  ],\n",
       "       [ 0.89217513,  0.07782486],\n",
       "       [ 0.09492671,  0.87507329],\n",
       "       [ 0.18851124,  0.78148876],\n",
       "       [ 0.8608005 ,  0.10919951],\n",
       "       [ 0.91994093,  0.05005908],\n",
       "       [ 0.91576318,  0.05423683],\n",
       "       [ 0.92215752,  0.04784248],\n",
       "       [ 0.66696692,  0.30303308],\n",
       "       [ 0.87387205,  0.09612795],\n",
       "       [ 0.80906013,  0.16093988],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.04688739,  0.92311261],\n",
       "       [ 0.30616856,  0.66383144],\n",
       "       [ 0.87867015,  0.09132985],\n",
       "       [ 0.11934686,  0.85065314],\n",
       "       [ 0.88958591,  0.0804141 ],\n",
       "       [ 0.89564958,  0.07435042],\n",
       "       [ 0.91824306,  0.05175694],\n",
       "       [ 0.91439992,  0.05560008],\n",
       "       [ 0.69762859,  0.27237141],\n",
       "       [ 0.13679955,  0.83320045],\n",
       "       [ 0.23973741,  0.73026259],\n",
       "       [ 0.39030224,  0.57969776],\n",
       "       [ 0.2765265 ,  0.6934735 ],\n",
       "       [ 0.90630285,  0.06369714],\n",
       "       [ 0.92108243,  0.04891757],\n",
       "       [ 0.72539699,  0.24460301],\n",
       "       [ 0.80883812,  0.16116189],\n",
       "       [ 0.90065085,  0.06934914],\n",
       "       [ 0.83696461,  0.13303538],\n",
       "       [ 0.52510601,  0.44489399],\n",
       "       [ 0.87626265,  0.09373736],\n",
       "       [ 0.45923928,  0.51076072],\n",
       "       [ 0.8668407 ,  0.10315929],\n",
       "       [ 0.82786747,  0.14213251],\n",
       "       [ 0.04966445,  0.92033555],\n",
       "       [ 0.82123332,  0.14876667],\n",
       "       [ 0.84837857,  0.12162142],\n",
       "       [ 0.76444872,  0.20555127],\n",
       "       [ 0.75018382,  0.21981619],\n",
       "       [ 0.65691399,  0.31308603],\n",
       "       [ 0.91806763,  0.05193237],\n",
       "       [ 0.91699109,  0.05300891],\n",
       "       [ 0.23973741,  0.73026259],\n",
       "       [ 0.09283301,  0.87716699],\n",
       "       [ 0.81357406,  0.15642594],\n",
       "       [ 0.25911713,  0.71088287],\n",
       "       [ 0.79168966,  0.17831033],\n",
       "       [ 0.66126871,  0.30873129],\n",
       "       [ 0.88599143,  0.08400858],\n",
       "       [ 0.73433268,  0.23566732],\n",
       "       [ 0.92215752,  0.04784248],\n",
       "       [ 0.53802904,  0.43197096],\n",
       "       [ 0.05466118,  0.91533882],\n",
       "       [ 0.22083838,  0.74916162],\n",
       "       [ 0.76330826,  0.20669174],\n",
       "       [ 0.86589758,  0.10410243],\n",
       "       [ 0.66812755,  0.30187245],\n",
       "       [ 0.8937154 ,  0.07628461],\n",
       "       [ 0.71772762,  0.25227238],\n",
       "       [ 0.60640397,  0.36359602],\n",
       "       [ 0.68597369,  0.28402631],\n",
       "       [ 0.47193432,  0.49806569],\n",
       "       [ 0.04294581,  0.92705419],\n",
       "       [ 0.89755524,  0.07244476],\n",
       "       [ 0.07252504,  0.89747496],\n",
       "       [ 0.84473286,  0.12526715],\n",
       "       [ 0.88243455,  0.08756545],\n",
       "       [ 0.91381153,  0.05618846],\n",
       "       [ 0.10088353,  0.86911647],\n",
       "       [ 0.38718877,  0.58281123],\n",
       "       [ 0.87867015,  0.09132985],\n",
       "       [ 0.22671218,  0.74328782],\n",
       "       [ 0.75968108,  0.21031893],\n",
       "       [ 0.71911301,  0.25088698],\n",
       "       [ 0.75609092,  0.21390907],\n",
       "       [ 0.90263661,  0.06736339],\n",
       "       [ 0.85750066,  0.11249935],\n",
       "       [ 0.47755485,  0.49244515],\n",
       "       [ 0.88274658,  0.08725343],\n",
       "       [ 0.8285    ,  0.1415    ],\n",
       "       [ 0.85167543,  0.11832458],\n",
       "       [ 0.02665384,  0.94334616],\n",
       "       [ 0.56378298,  0.40621702],\n",
       "       [ 0.29845333,  0.67154667],\n",
       "       [ 0.83630674,  0.13369327],\n",
       "       [ 0.40110194,  0.56889806],\n",
       "       [ 0.92053964,  0.04946037],\n",
       "       [ 0.0760483 ,  0.8939517 ],\n",
       "       [ 0.022274  ,  0.947726  ],\n",
       "       [ 0.89887057,  0.07112943],\n",
       "       [ 0.90363334,  0.06636667],\n",
       "       [ 0.8431394 ,  0.1268606 ],\n",
       "       [ 0.28330486,  0.68669514],\n",
       "       [ 0.70737945,  0.26262055],\n",
       "       [ 0.09323254,  0.87676746],\n",
       "       [ 0.90094794,  0.06905204],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.43607743,  0.53392257],\n",
       "       [ 0.78544466,  0.18455535],\n",
       "       [ 0.05741825,  0.91258175],\n",
       "       [ 0.05449832,  0.91550168],\n",
       "       [ 0.72221612,  0.24778388],\n",
       "       [ 0.02167583,  0.94832417],\n",
       "       [ 0.70290004,  0.26709996],\n",
       "       [ 0.90493835,  0.06506167],\n",
       "       [ 0.79123998,  0.17876002],\n",
       "       [ 0.03851327,  0.93148673],\n",
       "       [ 0.73353071,  0.23646928],\n",
       "       [ 0.91787476,  0.05212525],\n",
       "       [ 0.0143656 ,  0.9556344 ],\n",
       "       [ 0.89777397,  0.07222603],\n",
       "       [ 0.87254917,  0.09745083],\n",
       "       [ 0.03718756,  0.93281244],\n",
       "       [ 0.0555183 ,  0.9144817 ],\n",
       "       [ 0.67451776,  0.29548224],\n",
       "       [ 0.91123029,  0.05876971],\n",
       "       [ 0.88934602,  0.08065398],\n",
       "       [ 0.50520258,  0.46479742],\n",
       "       [ 0.87485401,  0.09514599],\n",
       "       [ 0.72735976,  0.24264024],\n",
       "       [ 0.53043957,  0.43956042],\n",
       "       [ 0.33112143,  0.63887857],\n",
       "       [ 0.80984963,  0.16015038],\n",
       "       [ 0.09419114,  0.87580886],\n",
       "       [ 0.86941766,  0.10058234],\n",
       "       [ 0.91092385,  0.05907615],\n",
       "       [ 0.86965599,  0.10034402],\n",
       "       [ 0.64677033,  0.32322968],\n",
       "       [ 0.46120499,  0.50879501],\n",
       "       [ 0.04246534,  0.92753466],\n",
       "       [ 0.30768788,  0.66231212],\n",
       "       [ 0.88677433,  0.08322566],\n",
       "       [ 0.90600439,  0.0639956 ],\n",
       "       [ 0.04964173,  0.92035827],\n",
       "       [ 0.8715869 ,  0.0984131 ],\n",
       "       [ 0.02321092,  0.94678908],\n",
       "       [ 0.86711244,  0.10288756],\n",
       "       [ 0.85863543,  0.11136457],\n",
       "       [ 0.06999587,  0.90000413],\n",
       "       [ 0.91159563,  0.05840436],\n",
       "       [ 0.04899694,  0.92100306],\n",
       "       [ 0.80545576,  0.16454425],\n",
       "       [ 0.66637373,  0.30362628],\n",
       "       [ 0.47479263,  0.49520737],\n",
       "       [ 0.89726847,  0.07273154],\n",
       "       [ 0.72526488,  0.24473514],\n",
       "       [ 0.28676638,  0.68323362],\n",
       "       [ 0.23142767,  0.73857233],\n",
       "       [ 0.23973741,  0.73026259],\n",
       "       [ 0.03908091,  0.93091909],\n",
       "       [ 0.46885222,  0.50114778],\n",
       "       [ 0.90065085,  0.06934914],\n",
       "       [ 0.07678791,  0.89321209],\n",
       "       [ 0.94203015,  0.02796986],\n",
       "       [ 0.90065085,  0.06934914],\n",
       "       [ 0.22468623,  0.74531377]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_soft.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_vc_hard = VotingClassifier(estimators=[('sam', sam), ('rf', rf), ('lg', lg), ('xg', xg)], \n",
    "                 voting='hard', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1  valid score:  0.865921787709\n",
      "fold  2  valid score:  0.831460674157\n",
      "fold  3  valid score:  0.837078651685\n",
      "fold  4  valid score:  0.831460674157\n",
      "fold  5  valid score:  0.803370786517\n",
      "5  fold(s) avg. valid score:  0.833858514845\n"
     ]
    }
   ],
   "source": [
    "cross_validate(final_vc_hard, train_x, train_y, 5, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sam', StackingAveragedModels(eval_func=<function accuracy_score at 0x000000000AFFC048>,\n",
       "            meta_model=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurit...      reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8))],\n",
       "         flatten_transform=None, n_jobs=2, voting='hard', weights=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_hard.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,\n",
       "        1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,\n",
       "        0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "        0.,  1.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_hard.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 versions of sbumissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_test = pd.read_csv('data/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = orig_test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_soft = pd.DataFrame()\n",
    "submission_soft['PassengerId'] = ID\n",
    "submission_soft['Survived'] = final_vc_soft.predict(test_x).astype('int')\n",
    "submission_soft.to_csv('submission_soft.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy =  0.902356902357\n"
     ]
    }
   ],
   "source": [
    "soft_pred = final_vc_soft.predict(train_x).astype('int')\n",
    "print(\"train accuracy = \", accuracy_score(train_y, soft_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_hard = pd.DataFrame()\n",
    "submission_hard['PassengerId'] = ID\n",
    "submission_hard['Survived'] = final_vc_hard.predict(test_x).astype('int')\n",
    "submission_hard.to_csv('submission_hard.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy =  0.895622895623\n"
     ]
    }
   ],
   "source": [
    "hard_pred = final_vc_hard.predict(train_x).astype('int')\n",
    "print(\"train accuracy = \", accuracy_score(train_y, hard_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('xg_submission.csv')\n",
    "test_pred = test['Survived']\n",
    "print(len(test_pred[test_pred != submission_soft['Survived']]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
