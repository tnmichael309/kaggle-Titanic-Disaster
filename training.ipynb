{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 42)\n",
      "(418, 41)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/preprocessed_train.csv')\n",
    "test = pd.read_csv('data/preprocessed_test.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(train.columns)\n",
    "\n",
    "target = 'Survived'\n",
    "features.remove(target)\n",
    "\n",
    "train_x = train[features]\n",
    "train_y = train[target]\n",
    "test_x = test[features]\n",
    "\n",
    "train_num = train_x.shape[0]\n",
    "test_num = test_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    549\n",
      "1.0    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dead_weight = 549/891.0\n",
    "survived_weight = 1.0 - dead_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperate into two groups, one can predict prob for soft voting classifier, another group cannot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 1: Classifiers with predict_prob functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log', penalty='elasticnet', class_weight = 'balanced', n_jobs=4,\n",
    "                    alpha=0.0005, l1_ratio=0.87, random_state=3, max_iter=100000, learning_rate='optimal')\n",
    "params = {\n",
    "    'alpha': [0.05, 0.01, 0.005, 0.001],\n",
    "    'l1_ratio': [1.0, 0.8, 0.6],\n",
    "    #'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=sgd, param_grid = params, scoring='accuracy', iid=False, cv=5, verbose=1)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 3} 0.786822089754\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log', penalty='elasticnet', class_weight = 'balanced', n_jobs=2,\n",
    "                    alpha=0.005, l1_ratio=1.0, random_state=3, max_iter=100000, learning_rate='optimal')\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=sgd, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2'} 0.809243996089\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight = 'balanced', random_state=3, max_iter=100000)\n",
    "\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "gs =  GridSearchCV(estimator=lr, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1} 0.809243996089\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight = 'balanced', penalty='l2', random_state=3, max_iter=100000)\n",
    "\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=lr, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lbfgs for small data set\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), solver='lbfgs', alpha=0.001, random_state=3, \n",
    "                    max_iter=10000)\n",
    "params = {\n",
    "    'alpha': [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.0005],\n",
    "}\n",
    "gs =  GridSearchCV(estimator=mlp, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 2} 0.804774864201\n"
     ]
    }
   ],
   "source": [
    "# use lbfgs for small data set\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), solver='lbfgs', alpha=0.005, random_state=3, \n",
    "                    max_iter=10000)\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=mlp, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 0.01, 'min_weight_fraction_leaf': 0.0, 'min_impurity_decrease': 0.001} 0.827221878816\n"
     ]
    }
   ],
   "source": [
    "# use lbfgs for small data set\n",
    "rf = RandomForestClassifier(n_estimators = 1200, n_jobs = 2, class_weight='balanced',\n",
    "                            random_state=3,\n",
    "                            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                            min_impurity_decrease=0.0,)\n",
    "params = {\n",
    "    'min_samples_split': [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3, 0.4, 0.49],\n",
    "    'min_impurity_decrease': [0.2, 0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "}\n",
    "gs =  GridSearchCV(estimator=rf, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1} 0.830586388263\n"
     ]
    }
   ],
   "source": [
    "# use lbfgs for small data set\n",
    "rf = RandomForestClassifier(n_estimators = 1200, n_jobs = 2, class_weight='balanced',\n",
    "                            random_state=3,\n",
    "                            min_samples_split=0.01, min_weight_fraction_leaf=0.0,\n",
    "                            min_impurity_decrease=0.001)\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=rf, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priors': [0.38383838383838387, 0.6161616161616161]} 0.790230751472\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(priors=[survived_weight, dead_weight])\n",
    "params = {\n",
    "    'priors': [[survived_weight, dead_weight], [.5, .5], [dead_weight, survived_weight]]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=nb, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'learning_rate': 0.01, 'subsample': 0.8} 0.839550044028\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=1, colsample_bytree=1,\n",
    "                      min_child_weight=0.0, gamma=0.0,\n",
    "                      reg_alpha=0, reg_lambda=1,random_state=0)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.05],\n",
    "    'subsample': [1.0, 0.8, 0.6], \n",
    "    'colsample_bytree': [1.0, 0.8, 0.6], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=xg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_weight': 0.175, 'gamma': 0.01} 0.840673639534\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=.8, colsample_bytree=.8,\n",
    "                      min_child_weight=0.0, gamma=0.0,\n",
    "                      reg_alpha=0, reg_lambda=1, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'min_child_weight': [0.01, 0.05, 0.1, 0.175, 0.2, 0.25, 0.3],\n",
    "    'gamma': [0.0, 0.01, 0.05, 0.1, 0.2, 0.4], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=xg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_lambda': 0.6, 'reg_alpha': 0.0} 0.841797235039\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=.8, colsample_bytree=.8,\n",
    "                      min_child_weight=0.175, gamma=0.01,\n",
    "                      reg_alpha=0, reg_lambda=1, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'reg_alpha': [0.0, .2, .4, .6, .8, 1.],\n",
    "    'reg_lambda': [0.0, .2, .4, .6, .8, 1.], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=xg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 5} 0.838383838384\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=.8, colsample_bytree=.8,\n",
    "                      min_child_weight=0.175, gamma=0.01,\n",
    "                      reg_alpha=0, reg_lambda=.6, random_state=0, objective='binary:logistic')\n",
    "\n",
    "params = {\n",
    "    'random_state': [0, 1, 2, 3, 4, 5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=xg, param_grid = params, scoring='accuracy', iid=False, cv=3)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6, 'learning_rate': 0.01, 'subsample': 0.2} 0.840648318472\n"
     ]
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.01, subsample = 1.0, colsample_bytree=1.0,\n",
    "                       min_child_samples = 1, min_child_weight=0.0, min_split_gain=0.01,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05],\n",
    "    'subsample': [1.0, 0.8, 0.6, 0.4, 0.2, 0.1], \n",
    "    'colsample_bytree': [1.0, 0.8, 0.6, 0.4, 0.2, 0.1], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=lg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_weight': 0.4, 'min_child_samples': 4, 'min_split_gain': 0.1} 0.848526112079\n"
     ]
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.01, subsample = .2, colsample_bytree=.6,\n",
    "                       min_child_samples = 1, min_child_weight=0.0, min_split_gain=0.01,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'min_child_samples': [1, 2, 4, 8, 16, 32],\n",
    "    'min_child_weight': [0.2, 0.4, 0.8, 1.6, 3.2], \n",
    "    'min_split_gain': [0.0, 0.01, 0.05, 0.1, 0.2, 0.4], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=lg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_lambda': 0.0, 'reg_alpha': 0.0} 0.848526112079\n"
     ]
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.01, subsample = .2, colsample_bytree=.6,\n",
    "                       min_child_samples = 4, min_child_weight=0.4, min_split_gain=0.1,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'reg_alpha': [0.0, .2, .4, .6, .8, 1.],\n",
    "    'reg_lambda': [0.0, .2, .4, .6, .8, 1.], \n",
    "}\n",
    "gs =  GridSearchCV(estimator=lg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 0} 0.848526112079\n"
     ]
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.01, subsample = .2, colsample_bytree=.6,\n",
    "                       min_child_samples = 4, min_child_weight=0.4, min_split_gain=0.1,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)\n",
    "\n",
    "params = {\n",
    "    'random_state': [0,1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=lg, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.776684338214\n",
    "lr = LogisticRegression(class_weight = 'balanced', penalty='l2', random_state=1, max_iter=100000)\n",
    "\n",
    "# 0.786822089754\n",
    "sgd = SGDClassifier(loss='log', penalty='elasticnet', class_weight = 'balanced', n_jobs=2,\n",
    "                    alpha=0.005, l1_ratio=1.0, random_state=3, max_iter=100000, learning_rate='optimal')\n",
    "\n",
    "# 0.790230751472\n",
    "nb = GaussianNB(priors=[survived_weight, dead_weight])\n",
    "\n",
    "# 0.804774864201\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,), solver='lbfgs', alpha=0.005, random_state=2, \n",
    "                    max_iter=10000)\n",
    "\n",
    "# 0.830586388263\n",
    "rf = RandomForestClassifier(n_estimators = 1200, n_jobs = 2, class_weight='balanced',\n",
    "                            random_state=1,\n",
    "                            min_samples_split=0.01, min_weight_fraction_leaf=0.0,\n",
    "                            min_impurity_decrease=0.001)\n",
    "\n",
    "# 0.841797235039\n",
    "xg = xgb.XGBClassifier(n_estimators = 1200, n_jobs=2,\n",
    "                       learning_rate=0.01, subsample=.8, colsample_bytree=.8,\n",
    "                      min_child_weight=0.175, gamma=0.01,\n",
    "                      reg_alpha=0, reg_lambda=.6, random_state=0, objective='binary:logistic')\n",
    "\n",
    "# 0.848526112079\n",
    "lg = lgb.LGBMClassifier(n_estimators=1200,\n",
    "                        learning_rate=0.01, subsample = .2, colsample_bytree=.6,\n",
    "                       min_child_samples = 4, min_child_weight=0.4, min_split_gain=0.1,\n",
    "                       reg_alpha=0, reg_lambda=.0, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 2: Classifiers without predict_prob functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.2} 0.777770129446\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier(alpha=1.0, normalize=True, class_weight='balanced', random_state=3, max_iter=10000)\n",
    "params = {\n",
    "    'alpha': [1.0, 0.8, 0.6, 0.4, 0.2],\n",
    "}\n",
    "gs =  GridSearchCV(estimator=ridge, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 1} 0.777770129446\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier(alpha=0.2, normalize=True, class_weight='balanced', random_state=3, max_iter=10000)\n",
    "params = {\n",
    "    'random_state': [1,2,3,4,5]\n",
    "}\n",
    "gs =  GridSearchCV(estimator=ridge, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.777770129446\n",
    "ridge = RidgeClassifier(alpha=0.2, normalize=True, class_weight='balanced', random_state=1, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Group1 + 2 (cv accuracy < 0.83) for voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use hard voting since these models are not well-calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VotingClassifier(estimators=[('lr', lr), ('sgd', sgd), ('nb', nb), ('mlp', mlp)], \n",
    "                 voting='hard', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79888268,  0.76536313,  0.80337079,  0.82022472,  0.8079096 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(vc, train_x, train_y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79915018399999993"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([ 0.79888268,  0.76536313,  0.80337079,  0.82022472,  0.8079096 ]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VotingClassifier(estimators=[('lr', lr), ('sgd', sgd), ('nb', nb), ('mlp', mlp)], \n",
    "                 voting='hard', n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Group1 + 2 (cv accuracy < 0.83) in the stacking averaged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stacking_models_api import StackingAveragedModels\n",
    "from cross_valid_api import cross_validate\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supervised_dict = {\n",
    "    'ridge': ridge,\n",
    "    'lr': lr,\n",
    "    'sgd': sgd,\n",
    "    'mlp': mlp,\n",
    "    'nb': nb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sam = StackingAveragedModels(sl_base_models_dict=supervised_dict, meta_model=rf, target_col='Survived', eval_func=accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.755244755245\n",
      "score= 0.762237762238\n",
      "score= 0.781690140845\n",
      "score= 0.788732394366\n",
      "score= 0.774647887324\n",
      "Avg score =  0.772510588004\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.755244755245\n",
      "score= 0.762237762238\n",
      "score= 0.781690140845\n",
      "score= 0.774647887324\n",
      "score= 0.781690140845\n",
      "Avg score =  0.771102137299\n",
      "\n",
      "==================\n",
      " nb\n",
      "score= 0.769230769231\n",
      "score= 0.762237762238\n",
      "score= 0.746478873239\n",
      "score= 0.788732394366\n",
      "score= 0.830985915493\n",
      "Avg score =  0.779533142913\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.741258741259\n",
      "score= 0.755244755245\n",
      "score= 0.746478873239\n",
      "score= 0.795774647887\n",
      "score= 0.802816901408\n",
      "Avg score =  0.768314783808\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.79020979021\n",
      "score= 0.811188811189\n",
      "score= 0.788732394366\n",
      "score= 0.802816901408\n",
      "score= 0.802816901408\n",
      "Avg score =  0.799152959716\n",
      "meta model's training set score=  0.799157303371 \n",
      "\n",
      "fold  1  valid score:  0.843575418994\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.769230769231\n",
      "score= 0.811188811189\n",
      "score= 0.734265734266\n",
      "score= 0.830985915493\n",
      "score= 0.774647887324\n",
      "Avg score =  0.7840638235\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.776223776224\n",
      "score= 0.804195804196\n",
      "score= 0.727272727273\n",
      "score= 0.80985915493\n",
      "score= 0.774647887324\n",
      "Avg score =  0.778439869989\n",
      "\n",
      "==================\n",
      " nb\n",
      "score= 0.783216783217\n",
      "score= 0.818181818182\n",
      "score= 0.748251748252\n",
      "score= 0.80985915493\n",
      "score= 0.781690140845\n",
      "Avg score =  0.788239929085\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.811188811189\n",
      "score= 0.825174825175\n",
      "score= 0.762237762238\n",
      "score= 0.823943661972\n",
      "score= 0.774647887324\n",
      "Avg score =  0.799438589579\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.776223776224\n",
      "score= 0.839160839161\n",
      "score= 0.797202797203\n",
      "score= 0.830985915493\n",
      "score= 0.781690140845\n",
      "Avg score =  0.805052693785\n",
      "meta model's training set score=  0.826086956522 \n",
      "\n",
      "fold  2  valid score:  0.792134831461\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.818181818182\n",
      "score= 0.769230769231\n",
      "score= 0.748251748252\n",
      "score= 0.760563380282\n",
      "score= 0.767605633803\n",
      "Avg score =  0.77276666995\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.818181818182\n",
      "score= 0.762237762238\n",
      "score= 0.748251748252\n",
      "score= 0.767605633803\n",
      "score= 0.760563380282\n",
      "Avg score =  0.771368068551\n",
      "\n",
      "==================\n",
      " nb\n",
      "score= 0.797202797203\n",
      "score= 0.769230769231\n",
      "score= 0.776223776224\n",
      "score= 0.774647887324\n",
      "score= 0.753521126761\n",
      "Avg score =  0.774165271348\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.811188811189\n",
      "score= 0.762237762238\n",
      "score= 0.755244755245\n",
      "score= 0.774647887324\n",
      "score= 0.774647887324\n",
      "Avg score =  0.775593420664\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.839160839161\n",
      "score= 0.811188811189\n",
      "score= 0.762237762238\n",
      "score= 0.767605633803\n",
      "score= 0.80985915493\n",
      "Avg score =  0.798010440264\n",
      "meta model's training set score=  0.806451612903 \n",
      "\n",
      "fold  3  valid score:  0.837078651685\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.811188811189\n",
      "score= 0.769230769231\n",
      "score= 0.79020979021\n",
      "score= 0.774647887324\n",
      "score= 0.802816901408\n",
      "Avg score =  0.789618831872\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.79020979021\n",
      "score= 0.776223776224\n",
      "score= 0.783216783217\n",
      "score= 0.781690140845\n",
      "score= 0.795774647887\n",
      "Avg score =  0.785423027677\n",
      "\n",
      "==================\n",
      " nb\n",
      "score= 0.818181818182\n",
      "score= 0.804195804196\n",
      "score= 0.783216783217\n",
      "score= 0.753521126761\n",
      "score= 0.816901408451\n",
      "Avg score =  0.795203388161\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.804195804196\n",
      "score= 0.79020979021\n",
      "score= 0.79020979021\n",
      "score= 0.746478873239\n",
      "score= 0.802816901408\n",
      "Avg score =  0.786782231853\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.811188811189\n",
      "score= 0.783216783217\n",
      "score= 0.811188811189\n",
      "score= 0.80985915493\n",
      "score= 0.774647887324\n",
      "Avg score =  0.79802028957\n",
      "meta model's training set score=  0.814866760168 \n",
      "\n",
      "fold  4  valid score:  0.752808988764\n",
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.769230769231\n",
      "score= 0.776223776224\n",
      "score= 0.811188811189\n",
      "score= 0.718309859155\n",
      "score= 0.823943661972\n",
      "Avg score =  0.779779375554\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.769230769231\n",
      "score= 0.762237762238\n",
      "score= 0.811188811189\n",
      "score= 0.739436619718\n",
      "score= 0.838028169014\n",
      "Avg score =  0.784024426278\n",
      "\n",
      "==================\n",
      " nb\n",
      "score= 0.762237762238\n",
      "score= 0.755244755245\n",
      "score= 0.853146853147\n",
      "score= 0.795774647887\n",
      "score= 0.838028169014\n",
      "Avg score =  0.800886437506\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.769230769231\n",
      "score= 0.776223776224\n",
      "score= 0.832167832168\n",
      "score= 0.795774647887\n",
      "score= 0.845070422535\n",
      "Avg score =  0.803693489609\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.797202797203\n",
      "score= 0.748251748252\n",
      "score= 0.846153846154\n",
      "score= 0.760563380282\n",
      "score= 0.852112676056\n",
      "Avg score =  0.800856889589\n",
      "meta model's training set score=  0.831697054698 \n",
      "\n",
      "fold  5  valid score:  0.780898876404\n",
      "5  fold(s) avg. valid score:  0.801299353462\n"
     ]
    }
   ],
   "source": [
    "cross_validate(sam, train_x, train_y, 5, scoring=accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CV result is slightly better when using stacking averaged model than using hard-voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_rf = RandomForestClassifier(n_estimators = 1200, n_jobs = 2, class_weight='balanced',\n",
    "                            random_state=1,\n",
    "                            min_samples_split=0.005, min_weight_fraction_leaf=0.0,\n",
    "                            min_impurity_decrease=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sam = StackingAveragedModels(sl_base_models_dict=supervised_dict, meta_model=meta_rf, target_col='Survived', eval_func=accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================\n",
      " ridge\n",
      "score= 0.821229050279\n",
      "score= 0.752808988764\n",
      "score= 0.741573033708\n",
      "score= 0.76404494382\n",
      "score= 0.803370786517\n",
      "Avg score =  0.776605360618\n",
      "\n",
      "==================\n",
      " lr\n",
      "score= 0.810055865922\n",
      "score= 0.76404494382\n",
      "score= 0.758426966292\n",
      "score= 0.747191011236\n",
      "score= 0.803370786517\n",
      "Avg score =  0.776617914757\n",
      "\n",
      "==================\n",
      " mlp\n",
      "score= 0.815642458101\n",
      "score= 0.820224719101\n",
      "score= 0.76404494382\n",
      "score= 0.792134831461\n",
      "score= 0.808988764045\n",
      "Avg score =  0.800207143306\n",
      "\n",
      "==================\n",
      " nb\n",
      "score= 0.804469273743\n",
      "score= 0.741573033708\n",
      "score= 0.758426966292\n",
      "score= 0.786516853933\n",
      "score= 0.85393258427\n",
      "Avg score =  0.788983742389\n",
      "\n",
      "==================\n",
      " sgd\n",
      "score= 0.810055865922\n",
      "score= 0.769662921348\n",
      "score= 0.76404494382\n",
      "score= 0.769662921348\n",
      "score= 0.825842696629\n",
      "Avg score =  0.787853869814\n"
     ]
    }
   ],
   "source": [
    "sam.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.803591470258 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.803591470258 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.81607696,  0.18392304],\n",
       "       [ 0.50928251,  0.49071749],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.4312676 ,  0.5687324 ],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.50928251,  0.49071749],\n",
       "       [ 0.50928251,  0.49071749],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.3610234 ,  0.6389766 ],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.3610234 ,  0.6389766 ],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.4312676 ,  0.5687324 ],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.22653133,  0.77346867],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.71644672,  0.28355328],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.22653133,  0.77346867],\n",
       "       [ 0.7840469 ,  0.2159531 ],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.69637848,  0.30362152],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.71644672,  0.28355328],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.3610234 ,  0.6389766 ],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.42121067,  0.57878933],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.4312676 ,  0.5687324 ],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.53703582,  0.46296418],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.71644672,  0.28355328],\n",
       "       [ 0.4312676 ,  0.5687324 ],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.22653133,  0.77346867],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.4312676 ,  0.5687324 ],\n",
       "       [ 0.39833963,  0.60166037],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.3610234 ,  0.6389766 ],\n",
       "       [ 0.7988388 ,  0.2011612 ],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.53927458,  0.46072542],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.42121067,  0.57878933],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.71644672,  0.28355328],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.4312676 ,  0.5687324 ],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.71644672,  0.28355328],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.42121067,  0.57878933],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.53927458,  0.46072542],\n",
       "       [ 0.4312676 ,  0.5687324 ],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.3610234 ,  0.6389766 ],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.3610234 ,  0.6389766 ],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.53382034,  0.46617966],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.42121067,  0.57878933],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.56778112,  0.43221888],\n",
       "       [ 0.69896875,  0.30103125],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.69896875,  0.30103125],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.4312676 ,  0.5687324 ],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.70609836,  0.29390164],\n",
       "       [ 0.3958224 ,  0.6041776 ],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.50928251,  0.49071749],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.36810826,  0.63189174],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.16752006,  0.83247994],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.81607696,  0.18392304],\n",
       "       [ 0.56778112,  0.43221888]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sam = StackingAveragedModels(sl_base_models_dict=supervised_dict, meta_model=meta_rf, target_col='Survived', eval_func=accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_vc = VotingClassifier(estimators=[('sam', sam), ('rf', rf), ('xg', xg), ('lg', lg)], \n",
    "                 voting='soft', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': array([ 1,  3,  9, 27], dtype=int32)} 0.848519905936\n"
     ]
    }
   ],
   "source": [
    "weights = np.arange(4)\n",
    "\n",
    "params = {\n",
    "    'weights': [weights, \n",
    "                np.power(1.5, weights), \n",
    "                np.power(2, weights),\n",
    "                np.power(2.5, weights),\n",
    "                np.power(3, weights),\n",
    "                np.power(3.5, weights),\n",
    "                np.power(4, weights),\n",
    "                np.power(4.5, weights),\n",
    "                np.power(5, weights),]\n",
    "}\n",
    "\n",
    "gs =  GridSearchCV(estimator=final_vc, param_grid = params, scoring='accuracy', iid=False, cv=5)\n",
    "gs.fit(train_x, train_y)\n",
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_vc_soft = VotingClassifier(estimators=[('sam', sam), ('rf', rf), ('xg', xg), ('lg', lg)], \n",
    "                 weights = [ 1,  3,  9, 27],\n",
    "                 voting='soft', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1  valid score:  0.871508379888\n",
      "fold  2  valid score:  0.814606741573\n",
      "fold  3  valid score:  0.85393258427\n",
      "fold  4  valid score:  0.825842696629\n",
      "fold  5  valid score:  0.803370786517\n",
      "5  fold(s) avg. valid score:  0.833852237775\n"
     ]
    }
   ],
   "source": [
    "cross_validate(final_vc_soft, train_x, train_y, 5, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sam', StackingAveragedModels(eval_func=<function accuracy_score at 0x000000000AFF7048>,\n",
       "            meta_model=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurit...=0, reg_lambda=0.0, silent=True, subsample=0.2,\n",
       "        subsample_for_bin=50000, subsample_freq=1))],\n",
       "         flatten_transform=None, n_jobs=2, voting='soft',\n",
       "         weights=[1, 3, 9, 27])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_soft.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_soft.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94485294,  0.03014706],\n",
       "       [ 0.85716361,  0.11783639],\n",
       "       [ 0.839345  ,  0.135655  ],\n",
       "       [ 0.70332417,  0.27167583],\n",
       "       [ 0.43338636,  0.54161364],\n",
       "       [ 0.89663759,  0.0783624 ],\n",
       "       [ 0.5667298 ,  0.4082702 ],\n",
       "       [ 0.88041882,  0.09458118],\n",
       "       [ 0.11769595,  0.85730405],\n",
       "       [ 0.95370744,  0.02129256],\n",
       "       [ 0.94568542,  0.02931458],\n",
       "       [ 0.94694435,  0.02805564],\n",
       "       [ 0.01546457,  0.95953543],\n",
       "       [ 0.94256768,  0.03243232],\n",
       "       [ 0.03614936,  0.93885064],\n",
       "       [ 0.03996621,  0.93503379],\n",
       "       [ 0.87679615,  0.09820385],\n",
       "       [ 0.68860454,  0.28639546],\n",
       "       [ 0.22852706,  0.74647294],\n",
       "       [ 0.45429703,  0.52070296],\n",
       "       [ 0.9178716 ,  0.0571284 ],\n",
       "       [ 0.59838973,  0.37661027],\n",
       "       [ 0.04087199,  0.93412801],\n",
       "       [ 0.75282841,  0.2221716 ],\n",
       "       [ 0.02144749,  0.95355251],\n",
       "       [ 0.95162838,  0.02337162],\n",
       "       [ 0.01398618,  0.96101382],\n",
       "       [ 0.81224838,  0.16275162],\n",
       "       [ 0.50709649,  0.46790351],\n",
       "       [ 0.86887228,  0.10612772],\n",
       "       [ 0.92086176,  0.05413824],\n",
       "       [ 0.87283512,  0.10216489],\n",
       "       [ 0.32565359,  0.64934641],\n",
       "       [ 0.45807347,  0.51692653],\n",
       "       [ 0.60529464,  0.36970535],\n",
       "       [ 0.85019537,  0.12480463],\n",
       "       [ 0.73762402,  0.23737598],\n",
       "       [ 0.82972713,  0.14527287],\n",
       "       [ 0.92250135,  0.05249865],\n",
       "       [ 0.49065166,  0.48434834],\n",
       "       [ 0.9286997 ,  0.04630031],\n",
       "       [ 0.26202161,  0.71297839],\n",
       "       [ 0.94751664,  0.02748336],\n",
       "       [ 0.07128836,  0.90371164],\n",
       "       [ 0.0185401 ,  0.9564599 ],\n",
       "       [ 0.88605039,  0.08894961],\n",
       "       [ 0.57319108,  0.40180893],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.0264798 ,  0.9485202 ],\n",
       "       [ 0.34013693,  0.63486307],\n",
       "       [ 0.65854567,  0.31645434],\n",
       "       [ 0.77119889,  0.2038011 ],\n",
       "       [ 0.08315396,  0.89184604],\n",
       "       [ 0.31551407,  0.65948593],\n",
       "       [ 0.76102011,  0.21397989],\n",
       "       [ 0.95271864,  0.02228135],\n",
       "       [ 0.91613299,  0.05886702],\n",
       "       [ 0.86753609,  0.10746391],\n",
       "       [ 0.8653818 ,  0.10961821],\n",
       "       [ 0.010966  ,  0.964034  ],\n",
       "       [ 0.92677533,  0.04822468],\n",
       "       [ 0.77164019,  0.20335981],\n",
       "       [ 0.91559562,  0.05940438],\n",
       "       [ 0.21232349,  0.76267651],\n",
       "       [ 0.25418401,  0.72081599],\n",
       "       [ 0.08824597,  0.88675403],\n",
       "       [ 0.25522652,  0.71977348],\n",
       "       [ 0.93168789,  0.04331211],\n",
       "       [ 0.55694627,  0.41805373],\n",
       "       [ 0.20451054,  0.77048946],\n",
       "       [ 0.23300524,  0.74199476],\n",
       "       [ 0.94925841,  0.02574159],\n",
       "       [ 0.21965597,  0.75534403],\n",
       "       [ 0.76609875,  0.20890125],\n",
       "       [ 0.01381367,  0.96118633],\n",
       "       [ 0.81672516,  0.15827484],\n",
       "       [ 0.9331026 ,  0.0418974 ],\n",
       "       [ 0.23281289,  0.74218711],\n",
       "       [ 0.89409196,  0.08090804],\n",
       "       [ 0.23300524,  0.74199476],\n",
       "       [ 0.05976745,  0.91523255],\n",
       "       [ 0.83910351,  0.13589649],\n",
       "       [ 0.86599126,  0.10900874],\n",
       "       [ 0.94568542,  0.02931458],\n",
       "       [ 0.68434466,  0.29065534],\n",
       "       [ 0.92436248,  0.05063751],\n",
       "       [ 0.06311848,  0.91188152],\n",
       "       [ 0.26392118,  0.71107882],\n",
       "       [ 0.19821223,  0.77678777],\n",
       "       [ 0.04564009,  0.92935991],\n",
       "       [ 0.48773889,  0.48726111],\n",
       "       [ 0.84176921,  0.13323079],\n",
       "       [ 0.058425  ,  0.916575  ],\n",
       "       [ 0.9331026 ,  0.0418974 ],\n",
       "       [ 0.74706138,  0.22793861],\n",
       "       [ 0.80922494,  0.16577506],\n",
       "       [ 0.03953028,  0.93546972],\n",
       "       [ 0.59278598,  0.38221403],\n",
       "       [ 0.44014683,  0.53485317],\n",
       "       [ 0.91609396,  0.05890604],\n",
       "       [ 0.02322035,  0.95177965],\n",
       "       [ 0.83991122,  0.13508877],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.75132319,  0.22367681],\n",
       "       [ 0.2012769 ,  0.7737231 ],\n",
       "       [ 0.93062455,  0.04437546],\n",
       "       [ 0.914442  ,  0.060558  ],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.90945548,  0.06554452],\n",
       "       [ 0.59205377,  0.38294623],\n",
       "       [ 0.94317365,  0.03182634],\n",
       "       [ 0.15490236,  0.82009764],\n",
       "       [ 0.01765043,  0.95734957],\n",
       "       [ 0.39512522,  0.57987478],\n",
       "       [ 0.07255971,  0.90244029],\n",
       "       [ 0.93521468,  0.03978532],\n",
       "       [ 0.93646208,  0.03853792],\n",
       "       [ 0.07851243,  0.89648757],\n",
       "       [ 0.59120412,  0.38379588],\n",
       "       [ 0.07037692,  0.90462308],\n",
       "       [ 0.05807881,  0.91692119],\n",
       "       [ 0.87784011,  0.09715988],\n",
       "       [ 0.0079244 ,  0.9670756 ],\n",
       "       [ 0.94043134,  0.03456865],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.37263609,  0.60236391],\n",
       "       [ 0.89274626,  0.08225373],\n",
       "       [ 0.16446256,  0.81053744],\n",
       "       [ 0.67767554,  0.29732446],\n",
       "       [ 0.92344233,  0.05155768],\n",
       "       [ 0.72875759,  0.24624241],\n",
       "       [ 0.81048254,  0.16451746],\n",
       "       [ 0.877577  ,  0.097423  ],\n",
       "       [ 0.94283088,  0.03216913],\n",
       "       [ 0.95008221,  0.02491779],\n",
       "       [ 0.92563531,  0.04936469],\n",
       "       [ 0.83686689,  0.13813311],\n",
       "       [ 0.89199822,  0.08300178],\n",
       "       [ 0.73814489,  0.23685511],\n",
       "       [ 0.95742583,  0.01757417],\n",
       "       [ 0.95901104,  0.01598896],\n",
       "       [ 0.02455905,  0.95044095],\n",
       "       [ 0.8227817 ,  0.1522183 ],\n",
       "       [ 0.90601466,  0.06898535],\n",
       "       [ 0.29921017,  0.67578984],\n",
       "       [ 0.89433674,  0.08066326],\n",
       "       [ 0.64933373,  0.32566626],\n",
       "       [ 0.92632403,  0.04867597],\n",
       "       [ 0.6048689 ,  0.37013111],\n",
       "       [ 0.87633168,  0.09866833],\n",
       "       [ 0.00939653,  0.96560347],\n",
       "       [ 0.91013929,  0.0648607 ],\n",
       "       [ 0.94872452,  0.02627549],\n",
       "       [ 0.4057092 ,  0.5692908 ],\n",
       "       [ 0.83680996,  0.13819004],\n",
       "       [ 0.90703823,  0.06796176],\n",
       "       [ 0.0581098 ,  0.9168902 ],\n",
       "       [ 0.57497729,  0.40002271],\n",
       "       [ 0.11261345,  0.86238655],\n",
       "       [ 0.6603866 ,  0.3146134 ],\n",
       "       [ 0.32142695,  0.65357305],\n",
       "       [ 0.17144573,  0.80355427],\n",
       "       [ 0.17487534,  0.80012466],\n",
       "       [ 0.94585202,  0.02914798],\n",
       "       [ 0.89901995,  0.07598005],\n",
       "       [ 0.64048541,  0.33451459],\n",
       "       [ 0.6078288 ,  0.3671712 ],\n",
       "       [ 0.95757273,  0.01742727],\n",
       "       [ 0.07631557,  0.89868443],\n",
       "       [ 0.79710294,  0.17789706],\n",
       "       [ 0.94991275,  0.02508725],\n",
       "       [ 0.26586433,  0.70913567],\n",
       "       [ 0.9292001 ,  0.0457999 ],\n",
       "       [ 0.87803526,  0.09696473],\n",
       "       [ 0.91164842,  0.06335158],\n",
       "       [ 0.05064715,  0.92435285],\n",
       "       [ 0.04963348,  0.92536652],\n",
       "       [ 0.74489208,  0.23010792],\n",
       "       [ 0.03728914,  0.93771086],\n",
       "       [ 0.04148537,  0.93351463],\n",
       "       [ 0.89409196,  0.08090804],\n",
       "       [ 0.47224598,  0.50275402],\n",
       "       [ 0.02070147,  0.95429853],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.0254775 ,  0.9495225 ],\n",
       "       [ 0.80869791,  0.1663021 ],\n",
       "       [ 0.18263573,  0.79236427],\n",
       "       [ 0.77092358,  0.20407642],\n",
       "       [ 0.92879889,  0.04620111],\n",
       "       [ 0.8100618 ,  0.1649382 ],\n",
       "       [ 0.84440154,  0.13059845],\n",
       "       [ 0.87605856,  0.09894144],\n",
       "       [ 0.42449041,  0.55050959],\n",
       "       [ 0.92612393,  0.04887608],\n",
       "       [ 0.05067465,  0.92432535],\n",
       "       [ 0.92686659,  0.04813341],\n",
       "       [ 0.02773835,  0.94726165],\n",
       "       [ 0.47037451,  0.50462549],\n",
       "       [ 0.93588993,  0.03911008],\n",
       "       [ 0.54107577,  0.43392422],\n",
       "       [ 0.21188943,  0.76311057],\n",
       "       [ 0.05562426,  0.91937574],\n",
       "       [ 0.7209532 ,  0.2540468 ],\n",
       "       [ 0.04248581,  0.93251419],\n",
       "       [ 0.93293318,  0.04206682],\n",
       "       [ 0.87063725,  0.10436275],\n",
       "       [ 0.40103732,  0.57396268],\n",
       "       [ 0.94041   ,  0.03458999],\n",
       "       [ 0.02844835,  0.94655165],\n",
       "       [ 0.94195471,  0.03304528],\n",
       "       [ 0.73127639,  0.24372361],\n",
       "       [ 0.947054  ,  0.027946  ],\n",
       "       [ 0.85277485,  0.12222515],\n",
       "       [ 0.14396938,  0.83103062],\n",
       "       [ 0.8375155 ,  0.1374845 ],\n",
       "       [ 0.53933599,  0.43566401],\n",
       "       [ 0.12670377,  0.84829623],\n",
       "       [ 0.93544153,  0.03955847],\n",
       "       [ 0.05702508,  0.91797492],\n",
       "       [ 0.9331026 ,  0.0418974 ],\n",
       "       [ 0.09489304,  0.88010696],\n",
       "       [ 0.92497042,  0.05002959],\n",
       "       [ 0.10279021,  0.87220979],\n",
       "       [ 0.88041605,  0.09458395],\n",
       "       [ 0.173386  ,  0.801614  ],\n",
       "       [ 0.44882741,  0.52617259],\n",
       "       [ 0.89031883,  0.08468116],\n",
       "       [ 0.19821223,  0.77678777],\n",
       "       [ 0.95788332,  0.01711668],\n",
       "       [ 0.91377546,  0.06122454],\n",
       "       [ 0.72818982,  0.24681018],\n",
       "       [ 0.03918635,  0.93581365],\n",
       "       [ 0.92687731,  0.04812268],\n",
       "       [ 0.79885114,  0.17614886],\n",
       "       [ 0.55242121,  0.42257879],\n",
       "       [ 0.89121701,  0.083783  ],\n",
       "       [ 0.83546027,  0.13953973],\n",
       "       [ 0.5123019 ,  0.4626981 ],\n",
       "       [ 0.1142162 ,  0.8607838 ],\n",
       "       [ 0.01176547,  0.96323453],\n",
       "       [ 0.26721852,  0.70778148],\n",
       "       [ 0.05569494,  0.91930506],\n",
       "       [ 0.35159171,  0.62340829],\n",
       "       [ 0.94554611,  0.02945389],\n",
       "       [ 0.43134599,  0.54365401],\n",
       "       [ 0.73167499,  0.24332502],\n",
       "       [ 0.17947079,  0.79552921],\n",
       "       [ 0.75273767,  0.22226233],\n",
       "       [ 0.07037692,  0.90462308],\n",
       "       [ 0.52287604,  0.45212396],\n",
       "       [ 0.04441736,  0.93058264],\n",
       "       [ 0.75859955,  0.21640045],\n",
       "       [ 0.39088342,  0.58411658],\n",
       "       [ 0.94500946,  0.02999054],\n",
       "       [ 0.94063787,  0.03436212],\n",
       "       [ 0.94991275,  0.02508725],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.92324917,  0.05175083],\n",
       "       [ 0.05907965,  0.91592035],\n",
       "       [ 0.92197009,  0.0530299 ],\n",
       "       [ 0.94229932,  0.03270068],\n",
       "       [ 0.92852132,  0.04647868],\n",
       "       [ 0.13488055,  0.84011945],\n",
       "       [ 0.08304477,  0.89195523],\n",
       "       [ 0.86291318,  0.11208682],\n",
       "       [ 0.94568542,  0.02931458],\n",
       "       [ 0.93976649,  0.0352335 ],\n",
       "       [ 0.94991275,  0.02508725],\n",
       "       [ 0.73762402,  0.23737598],\n",
       "       [ 0.91227263,  0.06272737],\n",
       "       [ 0.89277086,  0.08222914],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.03824434,  0.93675566],\n",
       "       [ 0.24689285,  0.72810715],\n",
       "       [ 0.88084855,  0.09415145],\n",
       "       [ 0.0744709 ,  0.9005291 ],\n",
       "       [ 0.89776088,  0.07723912],\n",
       "       [ 0.8964763 ,  0.07852369],\n",
       "       [ 0.94021617,  0.03478383],\n",
       "       [ 0.94027978,  0.03472021],\n",
       "       [ 0.84123972,  0.13376028],\n",
       "       [ 0.04912869,  0.92587131],\n",
       "       [ 0.19821223,  0.77678777],\n",
       "       [ 0.49804819,  0.47695181],\n",
       "       [ 0.20269777,  0.77230223],\n",
       "       [ 0.94377768,  0.03122232],\n",
       "       [ 0.94932205,  0.02567796],\n",
       "       [ 0.68527713,  0.28972287],\n",
       "       [ 0.80636815,  0.16863184],\n",
       "       [ 0.9331026 ,  0.0418974 ],\n",
       "       [ 0.88397274,  0.09102726],\n",
       "       [ 0.67484175,  0.30015825],\n",
       "       [ 0.87803526,  0.09696473],\n",
       "       [ 0.42966377,  0.54533623],\n",
       "       [ 0.88467544,  0.09032457],\n",
       "       [ 0.90381501,  0.07118499],\n",
       "       [ 0.03778091,  0.93721909],\n",
       "       [ 0.86887228,  0.10612772],\n",
       "       [ 0.8996586 ,  0.0753414 ],\n",
       "       [ 0.69605154,  0.27894846],\n",
       "       [ 0.78440243,  0.19059757],\n",
       "       [ 0.61917438,  0.35582561],\n",
       "       [ 0.94099001,  0.03400999],\n",
       "       [ 0.94615472,  0.02884528],\n",
       "       [ 0.19821223,  0.77678777],\n",
       "       [ 0.10318473,  0.87181527],\n",
       "       [ 0.87869921,  0.09630079],\n",
       "       [ 0.13817869,  0.83682131],\n",
       "       [ 0.81427619,  0.16072381],\n",
       "       [ 0.60579438,  0.36920563],\n",
       "       [ 0.89691839,  0.0780816 ],\n",
       "       [ 0.65879056,  0.31620944],\n",
       "       [ 0.94991275,  0.02508725],\n",
       "       [ 0.78136705,  0.19363295],\n",
       "       [ 0.05435438,  0.92064562],\n",
       "       [ 0.2729324 ,  0.7020676 ],\n",
       "       [ 0.84164927,  0.13335073],\n",
       "       [ 0.78836565,  0.18663435],\n",
       "       [ 0.47491007,  0.50008993],\n",
       "       [ 0.9051066 ,  0.0698934 ],\n",
       "       [ 0.75132319,  0.22367681],\n",
       "       [ 0.51350559,  0.46149441],\n",
       "       [ 0.75663879,  0.21836121],\n",
       "       [ 0.35189312,  0.62310688],\n",
       "       [ 0.01935989,  0.95564011],\n",
       "       [ 0.9296868 ,  0.04531319],\n",
       "       [ 0.05803622,  0.91696378],\n",
       "       [ 0.91907704,  0.05592296],\n",
       "       [ 0.88624937,  0.08875063],\n",
       "       [ 0.94408871,  0.03091128],\n",
       "       [ 0.08869618,  0.88630382],\n",
       "       [ 0.41581107,  0.55918893],\n",
       "       [ 0.88084855,  0.09415145],\n",
       "       [ 0.1834787 ,  0.7915213 ],\n",
       "       [ 0.79146986,  0.18353014],\n",
       "       [ 0.73923564,  0.23576436],\n",
       "       [ 0.74585657,  0.22914342],\n",
       "       [ 0.93299808,  0.04200192],\n",
       "       [ 0.87028914,  0.10471086],\n",
       "       [ 0.4242075 ,  0.5507925 ],\n",
       "       [ 0.85491777,  0.12008223],\n",
       "       [ 0.89093567,  0.08406433],\n",
       "       [ 0.92948573,  0.04551428],\n",
       "       [ 0.01899143,  0.95600857],\n",
       "       [ 0.56427736,  0.41072264],\n",
       "       [ 0.2349755 ,  0.7400245 ],\n",
       "       [ 0.89199822,  0.08300178],\n",
       "       [ 0.60033654,  0.37466346],\n",
       "       [ 0.94836926,  0.02663074],\n",
       "       [ 0.07657591,  0.89842409],\n",
       "       [ 0.01593853,  0.95906147],\n",
       "       [ 0.93293318,  0.04206682],\n",
       "       [ 0.93590804,  0.03909196],\n",
       "       [ 0.83296834,  0.14203166],\n",
       "       [ 0.16699452,  0.80800548],\n",
       "       [ 0.70401083,  0.27098917],\n",
       "       [ 0.08649164,  0.88850836],\n",
       "       [ 0.86557271,  0.10942729],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.40735792,  0.56764208],\n",
       "       [ 0.91828207,  0.05671793],\n",
       "       [ 0.02824532,  0.94675468],\n",
       "       [ 0.06767142,  0.90732858],\n",
       "       [ 0.70332417,  0.27167583],\n",
       "       [ 0.01308326,  0.96191674],\n",
       "       [ 0.83048727,  0.14451273],\n",
       "       [ 0.93519366,  0.03980633],\n",
       "       [ 0.72521343,  0.24978656],\n",
       "       [ 0.02609484,  0.94890516],\n",
       "       [ 0.64799478,  0.32700523],\n",
       "       [ 0.93934841,  0.03565158],\n",
       "       [ 0.00708074,  0.96791926],\n",
       "       [ 0.9112226 ,  0.0637774 ],\n",
       "       [ 0.90154945,  0.07345055],\n",
       "       [ 0.01322303,  0.96177697],\n",
       "       [ 0.04064494,  0.93435506],\n",
       "       [ 0.79088168,  0.18411833],\n",
       "       [ 0.94056837,  0.03443162],\n",
       "       [ 0.93489475,  0.04010526],\n",
       "       [ 0.36115325,  0.61384675],\n",
       "       [ 0.86885069,  0.10614931],\n",
       "       [ 0.70156045,  0.27343955],\n",
       "       [ 0.61614676,  0.35885323],\n",
       "       [ 0.28871206,  0.68628794],\n",
       "       [ 0.6383546 ,  0.33664539],\n",
       "       [ 0.05296947,  0.92203053],\n",
       "       [ 0.90960372,  0.06539628],\n",
       "       [ 0.94465212,  0.03034788],\n",
       "       [ 0.91431543,  0.06068457],\n",
       "       [ 0.63530261,  0.33969739],\n",
       "       [ 0.41309158,  0.56190842],\n",
       "       [ 0.02659712,  0.94840288],\n",
       "       [ 0.25387192,  0.72112808],\n",
       "       [ 0.90685665,  0.06814335],\n",
       "       [ 0.92577021,  0.04922979],\n",
       "       [ 0.02383607,  0.95116393],\n",
       "       [ 0.8967871 ,  0.0782129 ],\n",
       "       [ 0.00939864,  0.96560136],\n",
       "       [ 0.91734666,  0.05765335],\n",
       "       [ 0.9109613 ,  0.0640387 ],\n",
       "       [ 0.03661077,  0.93838923],\n",
       "       [ 0.94173625,  0.03326374],\n",
       "       [ 0.02967648,  0.94532352],\n",
       "       [ 0.84461843,  0.13038156],\n",
       "       [ 0.77952584,  0.19547416],\n",
       "       [ 0.32907277,  0.64592723],\n",
       "       [ 0.92954533,  0.04545468],\n",
       "       [ 0.79814158,  0.17685842],\n",
       "       [ 0.44745304,  0.52754696],\n",
       "       [ 0.10162912,  0.87337088],\n",
       "       [ 0.19821223,  0.77678777],\n",
       "       [ 0.01529648,  0.95970352],\n",
       "       [ 0.5027783 ,  0.4722217 ],\n",
       "       [ 0.9331026 ,  0.0418974 ],\n",
       "       [ 0.02231785,  0.95268215],\n",
       "       [ 0.96295764,  0.01204237],\n",
       "       [ 0.9331026 ,  0.0418974 ],\n",
       "       [ 0.12537587,  0.84962413]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_soft.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_vc_hard = VotingClassifier(estimators=[('sam', sam), ('rf', rf), ('xg', xg), ('lg', lg)], \n",
    "                 voting='hard', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1  valid score:  0.871508379888\n",
      "fold  2  valid score:  0.820224719101\n",
      "fold  3  valid score:  0.842696629213\n",
      "fold  4  valid score:  0.85393258427\n",
      "fold  5  valid score:  0.797752808989\n",
      "5  fold(s) avg. valid score:  0.837223024292\n"
     ]
    }
   ],
   "source": [
    "cross_validate(final_vc_hard, train_x, train_y, 5, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('sam', StackingAveragedModels(eval_func=<function accuracy_score at 0x000000000AFF7048>,\n",
       "            meta_model=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurit...=0, reg_lambda=0.0, silent=True, subsample=0.2,\n",
       "        subsample_for_bin=50000, subsample_freq=1))],\n",
       "         flatten_transform=None, n_jobs=2, voting='hard', weights=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_hard.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vc_hard.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.01, learning_rate=0.01,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=0.175, missing=None,\n",
       "       n_estimators=1200, n_jobs=2, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=0.6, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 versions of sbumissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_test = pd.read_csv('data/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = orig_test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_soft = pd.DataFrame()\n",
    "submission_soft['PassengerId'] = ID\n",
    "submission_soft['Survived'] = final_vc_soft.predict(test_x)\n",
    "submission_soft.to_csv('submission_soft.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_hard = pd.DataFrame()\n",
    "submission_hard['PassengerId'] = ID\n",
    "submission_hard['Survived'] = final_vc_hard.predict(test_x)\n",
    "submission_hard.to_csv('submission_hard.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_xg = pd.DataFrame()\n",
    "submission_xg['PassengerId'] = ID\n",
    "submission_xg['Survived'] = xg.predict(test_x)\n",
    "submission_xg.to_csv('submission_xg.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
